{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from sentiment_analysis.config import SentimentAnalysisConfig\n",
    "from sentiment_analysis.data_access import DataClass\n",
    "from sentiment_analysis.features import Features\n",
    "from sentiment_analysis.evaluation import CustomEvaluation\n",
    "from sentiment_analysis.utils.constants import (\n",
    "    TEXT,\n",
    "    TARGET,\n",
    "    ORIGINAL_TEXT,\n",
    "    SPLIT,\n",
    "    TRAIN,\n",
    "    VALID,\n",
    "    TEST,\n",
    "    PREDICTION\n",
    ")\n",
    "\n",
    "PARENT_PATH = Path(os.getcwd()).parent.absolute()\n",
    "FORMAT = \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    "logging.basicConfig(format=FORMAT, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 21:02:55,139 - sentiment_analysis.utils.utils - INFO - func:build took: 10.24 sec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Working with one of the best Shakespeare sourc...</td>\n",
       "      <td>neg</td>\n",
       "      <td>development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well...tremors I, the original started off in ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ouch! This one was a bit painful to sit throug...</td>\n",
       "      <td>neg</td>\n",
       "      <td>development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've seen some crappy movies in my life, but t...</td>\n",
       "      <td>neg</td>\n",
       "      <td>development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Carriers\" follows the exploits of two guys an...</td>\n",
       "      <td>neg</td>\n",
       "      <td>development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I had been looking forward to seeing this film...</td>\n",
       "      <td>neg</td>\n",
       "      <td>development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Effect(s) without cause is generally not possi...</td>\n",
       "      <td>neg</td>\n",
       "      <td>development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This picture started out with good intentions,...</td>\n",
       "      <td>neg</td>\n",
       "      <td>development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I chose to see this movie because it got a goo...</td>\n",
       "      <td>neg</td>\n",
       "      <td>development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This film has to be the worst I have ever seen...</td>\n",
       "      <td>neg</td>\n",
       "      <td>development</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment        Split\n",
       "0  Working with one of the best Shakespeare sourc...       neg  development\n",
       "1  Well...tremors I, the original started off in ...       neg  development\n",
       "2  Ouch! This one was a bit painful to sit throug...       neg  development\n",
       "3  I've seen some crappy movies in my life, but t...       neg  development\n",
       "4  \"Carriers\" follows the exploits of two guys an...       neg  development\n",
       "5  I had been looking forward to seeing this film...       neg  development\n",
       "6  Effect(s) without cause is generally not possi...       neg  development\n",
       "7  This picture started out with good intentions,...       neg  development\n",
       "8  I chose to see this movie because it got a goo...       neg  development\n",
       "9  This film has to be the worst I have ever seen...       neg  development"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = SentimentAnalysisConfig()\n",
    "config.CURRENT_PATH = PARENT_PATH\n",
    "\n",
    "data = DataClass(config)\n",
    "df = data.build()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 21:04:18,296 - sentiment_analysis.utils.utils - INFO - func:clean took: 1 min and                 23.04 sec\n",
      "2022-12-04 21:04:41,708 - sentiment_analysis.utils.utils - INFO - func:fit took: 23.29 sec\n",
      "2022-12-04 21:05:07,018 - sentiment_analysis.utils.utils - INFO - func:transform took: 25.31 sec\n",
      "2022-12-04 21:05:07,038 - sentiment_analysis.utils.utils - INFO - func:fit_transform took: 48.62 sec\n",
      "2022-12-04 21:05:09,861 - sentiment_analysis.utils.utils - INFO - func:transform took: 2.81 sec\n",
      "2022-12-04 21:05:37,174 - sentiment_analysis.utils.utils - INFO - func:transform took: 27.31 sec\n",
      "2022-12-04 21:05:50,616 - sentiment_analysis.utils.utils - INFO - func:build took: 2 min and                 55.37 sec\n"
     ]
    }
   ],
   "source": [
    "features = Features()\n",
    "df_features = features.build(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Split</th>\n",
       "      <th>Original Text</th>\n",
       "      <th>char__ 00</th>\n",
       "      <th>char__ 1</th>\n",
       "      <th>char__ 10</th>\n",
       "      <th>char__ 11</th>\n",
       "      <th>char__ 12</th>\n",
       "      <th>char__ 13</th>\n",
       "      <th>...</th>\n",
       "      <th>word__york city</th>\n",
       "      <th>word__youll see</th>\n",
       "      <th>word__young boy</th>\n",
       "      <th>word__young girl</th>\n",
       "      <th>word__young man</th>\n",
       "      <th>word__young woman</th>\n",
       "      <th>word__youre going</th>\n",
       "      <th>word__youre looking</th>\n",
       "      <th>word__youve got</th>\n",
       "      <th>word__youve seen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tolerant really bad sci fi horror movie ive wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>I am very tolerant of really bad sci/fi and ho...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wow good movie acting wasnt good look moment f...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>wow! this is a good movie! The acting wasn't g...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>whatever rating give boom superb location phot...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>Whatever rating I give BOOM is only because of...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 5004 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  Split  \\\n",
       "0  tolerant really bad sci fi horror movie ive wa...          0  train   \n",
       "1  wow good movie acting wasnt good look moment f...          1  train   \n",
       "2  whatever rating give boom superb location phot...          0  train   \n",
       "\n",
       "                                       Original Text  char__ 00  char__ 1   \\\n",
       "0  I am very tolerant of really bad sci/fi and ho...        0.0        0.0   \n",
       "1  wow! this is a good movie! The acting wasn't g...        0.0        0.0   \n",
       "2  Whatever rating I give BOOM is only because of...        0.0        0.0   \n",
       "\n",
       "   char__ 10  char__ 11  char__ 12  char__ 13  ...  word__york city  \\\n",
       "0        0.0        0.0        0.0        0.0  ...              0.0   \n",
       "1        0.0        0.0        0.0        0.0  ...              0.0   \n",
       "2        0.0        0.0        0.0        0.0  ...              0.0   \n",
       "\n",
       "   word__youll see  word__young boy  word__young girl  word__young man  \\\n",
       "0              0.0              0.0               0.0              0.0   \n",
       "1              0.0              0.0               0.0              0.0   \n",
       "2              0.0              0.0               0.0              0.0   \n",
       "\n",
       "   word__young woman  word__youre going  word__youre looking  word__youve got  \\\n",
       "0                0.0                0.0                  0.0              0.0   \n",
       "1                0.0                0.0                  0.0              0.0   \n",
       "2                0.0                0.0                  0.0              0.0   \n",
       "\n",
       "   word__youve seen  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "\n",
       "[3 rows x 5004 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 5,000\n",
      "Number of training samples: 22,500\n",
      "Training set label distribution: pos:0.50, neg:0.50\n",
      "Number of validation samples: 2,500\n",
      "Validation set label distribution: pos:0.50, neg:0.50\n"
     ]
    }
   ],
   "source": [
    "train = df_features[df_features[SPLIT].isin([TRAIN])].copy()\n",
    "valid = df_features[df_features[SPLIT].isin([VALID])].copy()\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "valid.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_train = train[features.vectorizer.get_feature_names_out()].copy()\n",
    "X_valid = valid[features.vectorizer.get_feature_names_out()].copy()\n",
    "Y_train = train[TARGET]\n",
    "Y_valid = valid[TARGET]\n",
    "\n",
    "pos_prob_train = sum(Y_train) / len(Y_train)\n",
    "pos_prob_valid = sum(Y_train) / len(Y_train)\n",
    "print(f\"Number of features: {X_train.shape[1]:,}\")\n",
    "print(f\"Number of training samples: {X_train.shape[0]:,}\")\n",
    "print(f\"Training set label distribution: pos:{pos_prob_train:0.2f}, neg:{1-pos_prob_train:0.2f}\")\n",
    "print(f\"Number of validation samples: {X_valid.shape[0]:,}\")\n",
    "print(f\"Validation set label distribution: pos:{pos_prob_valid:0.2f}, neg:{1-pos_prob_valid:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train with early stopping on validation step\n",
    "\n",
    "This will help us discover the optimal boosting rounds. Once complete, we can train on the whole train + validation set using the discovered boosting rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-accuracy:0.70080\n",
      "[10]\tvalidation-accuracy:0.71160\n",
      "[20]\tvalidation-accuracy:0.71120\n",
      "[30]\tvalidation-accuracy:0.71880\n",
      "[40]\tvalidation-accuracy:0.73240\n",
      "[50]\tvalidation-accuracy:0.73360\n",
      "[60]\tvalidation-accuracy:0.74200\n",
      "[70]\tvalidation-accuracy:0.73840\n",
      "[80]\tvalidation-accuracy:0.74480\n",
      "[90]\tvalidation-accuracy:0.74600\n",
      "[100]\tvalidation-accuracy:0.74840\n",
      "[110]\tvalidation-accuracy:0.75240\n",
      "[120]\tvalidation-accuracy:0.75440\n",
      "[130]\tvalidation-accuracy:0.75800\n",
      "[140]\tvalidation-accuracy:0.75920\n",
      "[150]\tvalidation-accuracy:0.76120\n",
      "[160]\tvalidation-accuracy:0.76480\n",
      "[170]\tvalidation-accuracy:0.76800\n",
      "[180]\tvalidation-accuracy:0.77000\n",
      "[190]\tvalidation-accuracy:0.77240\n",
      "[200]\tvalidation-accuracy:0.77440\n",
      "[210]\tvalidation-accuracy:0.77520\n",
      "[220]\tvalidation-accuracy:0.77680\n",
      "[230]\tvalidation-accuracy:0.78160\n",
      "[240]\tvalidation-accuracy:0.78120\n",
      "[250]\tvalidation-accuracy:0.78360\n",
      "[260]\tvalidation-accuracy:0.78480\n",
      "[270]\tvalidation-accuracy:0.78480\n",
      "[280]\tvalidation-accuracy:0.78640\n",
      "[290]\tvalidation-accuracy:0.79000\n",
      "[300]\tvalidation-accuracy:0.78880\n",
      "[310]\tvalidation-accuracy:0.79080\n",
      "[320]\tvalidation-accuracy:0.79200\n",
      "[330]\tvalidation-accuracy:0.79320\n",
      "[340]\tvalidation-accuracy:0.79400\n",
      "[350]\tvalidation-accuracy:0.79520\n",
      "[360]\tvalidation-accuracy:0.79840\n",
      "[370]\tvalidation-accuracy:0.79960\n",
      "[380]\tvalidation-accuracy:0.80040\n",
      "[390]\tvalidation-accuracy:0.80200\n",
      "[400]\tvalidation-accuracy:0.80280\n",
      "[410]\tvalidation-accuracy:0.80280\n",
      "[420]\tvalidation-accuracy:0.80400\n",
      "[430]\tvalidation-accuracy:0.80560\n",
      "[440]\tvalidation-accuracy:0.80720\n",
      "[450]\tvalidation-accuracy:0.80720\n",
      "[460]\tvalidation-accuracy:0.80840\n",
      "[470]\tvalidation-accuracy:0.80880\n",
      "[480]\tvalidation-accuracy:0.81000\n",
      "[490]\tvalidation-accuracy:0.81200\n",
      "[500]\tvalidation-accuracy:0.81280\n",
      "[510]\tvalidation-accuracy:0.81480\n",
      "[520]\tvalidation-accuracy:0.81600\n",
      "[530]\tvalidation-accuracy:0.81560\n",
      "[540]\tvalidation-accuracy:0.81520\n",
      "[550]\tvalidation-accuracy:0.81640\n",
      "[560]\tvalidation-accuracy:0.81720\n",
      "[570]\tvalidation-accuracy:0.81840\n",
      "[580]\tvalidation-accuracy:0.81880\n",
      "[590]\tvalidation-accuracy:0.82000\n",
      "[600]\tvalidation-accuracy:0.82160\n",
      "[610]\tvalidation-accuracy:0.82240\n",
      "[620]\tvalidation-accuracy:0.82360\n",
      "[630]\tvalidation-accuracy:0.82400\n",
      "[640]\tvalidation-accuracy:0.82480\n",
      "[650]\tvalidation-accuracy:0.82600\n",
      "[660]\tvalidation-accuracy:0.82720\n",
      "[670]\tvalidation-accuracy:0.82880\n",
      "[680]\tvalidation-accuracy:0.82960\n",
      "[690]\tvalidation-accuracy:0.82880\n",
      "[700]\tvalidation-accuracy:0.82880\n",
      "[710]\tvalidation-accuracy:0.82960\n",
      "[720]\tvalidation-accuracy:0.83000\n",
      "[730]\tvalidation-accuracy:0.83000\n",
      "[740]\tvalidation-accuracy:0.83000\n",
      "[750]\tvalidation-accuracy:0.83040\n",
      "[760]\tvalidation-accuracy:0.83120\n",
      "[770]\tvalidation-accuracy:0.83160\n",
      "[780]\tvalidation-accuracy:0.83160\n",
      "[790]\tvalidation-accuracy:0.83240\n",
      "[800]\tvalidation-accuracy:0.83280\n",
      "[810]\tvalidation-accuracy:0.83360\n",
      "[820]\tvalidation-accuracy:0.83320\n",
      "[830]\tvalidation-accuracy:0.83240\n",
      "[840]\tvalidation-accuracy:0.83320\n",
      "[850]\tvalidation-accuracy:0.83440\n",
      "[860]\tvalidation-accuracy:0.83400\n",
      "[870]\tvalidation-accuracy:0.83480\n",
      "[880]\tvalidation-accuracy:0.83360\n",
      "[890]\tvalidation-accuracy:0.83480\n",
      "[900]\tvalidation-accuracy:0.83480\n",
      "[910]\tvalidation-accuracy:0.83560\n",
      "[920]\tvalidation-accuracy:0.83600\n",
      "[930]\tvalidation-accuracy:0.83640\n",
      "[940]\tvalidation-accuracy:0.83640\n",
      "[950]\tvalidation-accuracy:0.83720\n",
      "[960]\tvalidation-accuracy:0.83800\n",
      "[970]\tvalidation-accuracy:0.83800\n",
      "[980]\tvalidation-accuracy:0.83760\n",
      "[990]\tvalidation-accuracy:0.83880\n",
      "[1000]\tvalidation-accuracy:0.83960\n",
      "[1010]\tvalidation-accuracy:0.83880\n",
      "[1020]\tvalidation-accuracy:0.83880\n",
      "[1030]\tvalidation-accuracy:0.83920\n",
      "[1040]\tvalidation-accuracy:0.83960\n",
      "[1050]\tvalidation-accuracy:0.84000\n",
      "[1060]\tvalidation-accuracy:0.84080\n",
      "[1070]\tvalidation-accuracy:0.84080\n",
      "[1080]\tvalidation-accuracy:0.84080\n",
      "[1090]\tvalidation-accuracy:0.84120\n",
      "[1100]\tvalidation-accuracy:0.84280\n",
      "[1110]\tvalidation-accuracy:0.84320\n",
      "[1120]\tvalidation-accuracy:0.84240\n",
      "[1130]\tvalidation-accuracy:0.84280\n",
      "[1140]\tvalidation-accuracy:0.84320\n",
      "[1150]\tvalidation-accuracy:0.84240\n",
      "[1160]\tvalidation-accuracy:0.84320\n",
      "[1170]\tvalidation-accuracy:0.84280\n",
      "[1180]\tvalidation-accuracy:0.84360\n",
      "[1190]\tvalidation-accuracy:0.84360\n",
      "[1200]\tvalidation-accuracy:0.84360\n",
      "[1210]\tvalidation-accuracy:0.84440\n",
      "[1220]\tvalidation-accuracy:0.84400\n",
      "[1230]\tvalidation-accuracy:0.84400\n",
      "[1240]\tvalidation-accuracy:0.84400\n",
      "[1250]\tvalidation-accuracy:0.84440\n",
      "[1260]\tvalidation-accuracy:0.84520\n",
      "[1270]\tvalidation-accuracy:0.84520\n",
      "[1280]\tvalidation-accuracy:0.84640\n",
      "[1290]\tvalidation-accuracy:0.84560\n",
      "[1300]\tvalidation-accuracy:0.84600\n",
      "[1310]\tvalidation-accuracy:0.84600\n",
      "[1320]\tvalidation-accuracy:0.84680\n",
      "[1330]\tvalidation-accuracy:0.84600\n",
      "[1340]\tvalidation-accuracy:0.84720\n",
      "[1350]\tvalidation-accuracy:0.84720\n",
      "[1360]\tvalidation-accuracy:0.84800\n",
      "[1370]\tvalidation-accuracy:0.84880\n",
      "[1380]\tvalidation-accuracy:0.84920\n",
      "[1390]\tvalidation-accuracy:0.84880\n",
      "[1400]\tvalidation-accuracy:0.84960\n",
      "[1410]\tvalidation-accuracy:0.84920\n",
      "[1420]\tvalidation-accuracy:0.84960\n",
      "[1430]\tvalidation-accuracy:0.85040\n",
      "[1440]\tvalidation-accuracy:0.85000\n",
      "[1450]\tvalidation-accuracy:0.85000\n",
      "[1460]\tvalidation-accuracy:0.85080\n",
      "[1470]\tvalidation-accuracy:0.85160\n",
      "[1480]\tvalidation-accuracy:0.85120\n",
      "[1490]\tvalidation-accuracy:0.85160\n",
      "[1500]\tvalidation-accuracy:0.85200\n",
      "[1510]\tvalidation-accuracy:0.85360\n",
      "[1520]\tvalidation-accuracy:0.85320\n",
      "[1530]\tvalidation-accuracy:0.85320\n",
      "[1540]\tvalidation-accuracy:0.85480\n",
      "[1550]\tvalidation-accuracy:0.85480\n",
      "[1560]\tvalidation-accuracy:0.85480\n",
      "[1570]\tvalidation-accuracy:0.85520\n",
      "[1580]\tvalidation-accuracy:0.85480\n",
      "[1590]\tvalidation-accuracy:0.85440\n",
      "[1600]\tvalidation-accuracy:0.85480\n",
      "[1610]\tvalidation-accuracy:0.85440\n",
      "[1620]\tvalidation-accuracy:0.85520\n",
      "[1630]\tvalidation-accuracy:0.85560\n",
      "[1640]\tvalidation-accuracy:0.85520\n",
      "[1650]\tvalidation-accuracy:0.85640\n",
      "[1660]\tvalidation-accuracy:0.85680\n",
      "[1670]\tvalidation-accuracy:0.85600\n",
      "[1680]\tvalidation-accuracy:0.85600\n",
      "[1690]\tvalidation-accuracy:0.85560\n",
      "[1700]\tvalidation-accuracy:0.85640\n",
      "[1710]\tvalidation-accuracy:0.85640\n",
      "[1720]\tvalidation-accuracy:0.85640\n",
      "[1730]\tvalidation-accuracy:0.85600\n",
      "[1740]\tvalidation-accuracy:0.85600\n",
      "[1750]\tvalidation-accuracy:0.85600\n",
      "[1760]\tvalidation-accuracy:0.85640\n",
      "[1770]\tvalidation-accuracy:0.85680\n",
      "[1780]\tvalidation-accuracy:0.85720\n",
      "[1790]\tvalidation-accuracy:0.85680\n",
      "[1800]\tvalidation-accuracy:0.85720\n",
      "[1810]\tvalidation-accuracy:0.85680\n",
      "[1820]\tvalidation-accuracy:0.85720\n",
      "[1830]\tvalidation-accuracy:0.85800\n",
      "[1840]\tvalidation-accuracy:0.85840\n",
      "[1850]\tvalidation-accuracy:0.85800\n",
      "[1860]\tvalidation-accuracy:0.85760\n",
      "[1870]\tvalidation-accuracy:0.85760\n",
      "[1880]\tvalidation-accuracy:0.85760\n",
      "[1890]\tvalidation-accuracy:0.85800\n",
      "[1900]\tvalidation-accuracy:0.85920\n",
      "[1910]\tvalidation-accuracy:0.85960\n",
      "[1920]\tvalidation-accuracy:0.85920\n",
      "[1930]\tvalidation-accuracy:0.85880\n",
      "[1940]\tvalidation-accuracy:0.85880\n",
      "[1950]\tvalidation-accuracy:0.85840\n",
      "[1960]\tvalidation-accuracy:0.85920\n",
      "[1970]\tvalidation-accuracy:0.85920\n",
      "[1980]\tvalidation-accuracy:0.85880\n",
      "[1990]\tvalidation-accuracy:0.85920\n",
      "[2000]\tvalidation-accuracy:0.85880\n",
      "[2010]\tvalidation-accuracy:0.85880\n",
      "[2020]\tvalidation-accuracy:0.85880\n",
      "[2030]\tvalidation-accuracy:0.86000\n",
      "[2040]\tvalidation-accuracy:0.85960\n",
      "[2050]\tvalidation-accuracy:0.86000\n",
      "[2060]\tvalidation-accuracy:0.86040\n",
      "[2070]\tvalidation-accuracy:0.86080\n",
      "[2080]\tvalidation-accuracy:0.86200\n",
      "[2090]\tvalidation-accuracy:0.86080\n",
      "[2100]\tvalidation-accuracy:0.86160\n",
      "[2110]\tvalidation-accuracy:0.86080\n",
      "[2120]\tvalidation-accuracy:0.86040\n",
      "[2130]\tvalidation-accuracy:0.86080\n",
      "[2140]\tvalidation-accuracy:0.86120\n",
      "[2150]\tvalidation-accuracy:0.86040\n",
      "[2160]\tvalidation-accuracy:0.86080\n",
      "[2170]\tvalidation-accuracy:0.86080\n",
      "[2180]\tvalidation-accuracy:0.86000\n",
      "[2190]\tvalidation-accuracy:0.86040\n",
      "[2200]\tvalidation-accuracy:0.85920\n",
      "[2210]\tvalidation-accuracy:0.85960\n",
      "[2220]\tvalidation-accuracy:0.85960\n",
      "[2229]\tvalidation-accuracy:0.86000\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset for training and validation\n",
    "d_train = xgb.DMatrix(X_train, Y_train)\n",
    "d_val = xgb.DMatrix(X_valid, Y_valid)\n",
    "evals = [(d_val, \"validation\")]\n",
    "\n",
    "# Evaluation class to access custom objective and evaluation metric\n",
    "eval = CustomEvaluation()\n",
    "\n",
    "model = xgb.train(\n",
    "    params=config.XGB_PARAMETERS,\n",
    "    dtrain=d_train,\n",
    "    num_boost_round=config.XGB_NUM_BOOST_ROUND,\n",
    "    evals=evals,\n",
    "    obj=eval.binary_logistic,\n",
    "    custom_metric=eval.accuracy_eval,\n",
    "    maximize=True,\n",
    "    early_stopping_rounds=config.XGB_EARLY_STOPPING_ROUNDS,\n",
    "    verbose_eval=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learnt boosting rounds after validation: 2,080\n"
     ]
    }
   ],
   "source": [
    "num_boost_rounds = model.best_iteration\n",
    "print(f\"Learnt boosting rounds after validation: {num_boost_rounds:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the threshold which maximizes the accuracy on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting threshold to: 0.01\n"
     ]
    }
   ],
   "source": [
    "Y_valid_pred_probab = model.predict(xgb.DMatrix(X_valid))\n",
    "\n",
    "threshold = eval.threshold_discovery(y_true=Y_valid.to_numpy(), y_pred_probab=Y_valid_pred_probab)\n",
    "print(f\"Setting threshold to: {threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy     0.860000\n",
       "Precision    0.847104\n",
       "Recall       0.878303\n",
       "F1 Score     0.862421\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_valid_pred = np.where(Y_valid_pred_probab > threshold, 1, 0)\n",
    "\n",
    "eval.evaluate(y_true=Y_valid.to_numpy(), y_pred=Y_valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy     0.855440\n",
       "Precision    0.848361\n",
       "Recall       0.865600\n",
       "F1 Score     0.856894\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df_features[df_features[SPLIT].isin([TEST])].copy()\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_test = test[features.vectorizer.get_feature_names_out()].copy()\n",
    "Y_test = test[TARGET]\n",
    "\n",
    "Y_test_pred_probab = model.predict(xgb.DMatrix(X_test))\n",
    "Y_test_pred = np.where(Y_test_pred_probab > threshold, 1, 0)\n",
    "\n",
    "eval.evaluate(y_true=Y_test.to_numpy(), y_pred=Y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = test[[ORIGINAL_TEXT, TARGET]].copy()\n",
    "pred_df[PREDICTION] = Y_test_pred.reshape(-1,)\n",
    "save_to = os.path.join(data.reports_path, \"xgboost-prediction.pkl\")\n",
    "pred_df.to_pickle(save_to)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4147dedb0d2f4fd7bd9f9daaae1bb896b5adcf74c54646418d2fdc1ab4f35694"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
