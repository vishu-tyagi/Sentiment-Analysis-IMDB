{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import random\n",
    "import textwrap\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.express as px\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from sentiment_analysis.config import SentimentAnalysisConfig\n",
    "from sentiment_analysis.data_access import DataClass\n",
    "from sentiment_analysis.features import Features\n",
    "from sentiment_analysis.evaluation import CustomEvaluation\n",
    "from sentiment_analysis.utils.constants import (\n",
    "    TEXT,\n",
    "    TARGET,\n",
    "    ORIGINAL_TEXT,\n",
    "    SPLIT,\n",
    "    TRAIN,\n",
    "    VALID,\n",
    "    TEST,\n",
    "    SAVED_MODELS,\n",
    "    PREDICTION\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "sns.set_style(\"darkgrid\")\n",
    "PARENT_PATH = Path(os.getcwd()).parent.absolute()\n",
    "FORMAT = \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    "logging.basicConfig(format=FORMAT, level=logging.INFO)\n",
    "\n",
    "seed = 128\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SentimentAnalysisConfig()\n",
    "config.CURRENT_PATH = PARENT_PATH\n",
    "\n",
    "data = DataClass(config)\n",
    "df = data.build()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_features[df_features[SPLIT].isin([TRAIN])].copy()\n",
    "valid = df_features[df_features[SPLIT].isin([VALID])].copy()\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "valid.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_train = train[features.vectorizer.get_feature_names_out()].copy()\n",
    "X_valid = valid[features.vectorizer.get_feature_names_out()].copy()\n",
    "Y_train = train[TARGET]\n",
    "Y_valid = valid[TARGET]\n",
    "\n",
    "pos_prob_train = sum(Y_train) / len(Y_train)\n",
    "pos_prob_valid = sum(Y_train) / len(Y_train)\n",
    "print(f\"Number of features: {X_train.shape[1]:,}\")\n",
    "print(f\"Number of training samples: {X_train.shape[0]:,}\")\n",
    "print(f\"Training set label distribution: pos:{pos_prob_train:0.2f}, neg:{1-pos_prob_train:0.2f}\")\n",
    "print(f\"Number of validation samples: {X_valid.shape[0]:,}\")\n",
    "print(f\"Validation set label distribution: pos:{pos_prob_valid:0.2f}, neg:{1-pos_prob_valid:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        model_name: str,\n",
    "        max_length: int = 128\n",
    "    ):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.data = data\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        row = self.data.iloc[index]\n",
    "        text = row[ORIGINAL_TEXT]\n",
    "        target = np.array(row[TARGET]).reshape(-1,)\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=self.max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=True,\n",
    "        return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"text\": text,\n",
    "            \"input_ids\": inputs[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].flatten(),\n",
    "            \"token_type_ids\": inputs[\"token_type_ids\"].flatten(),\n",
    "            \"target\": torch.FloatTensor(target)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the pre-trained model with classifier head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, model_name: str):\n",
    "        super().__init__()\n",
    "        self.l1 = AutoModel.from_pretrained(model_name)\n",
    "        self.l2 = nn.Dropout(0.3)\n",
    "        self.l3 = nn.Linear(self.l1.config.hidden_size, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        out = self.l1(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        out = self.l2(out.pooler_output)\n",
    "        out = self.l3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose model and load the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Token-length analysis based on tokenizer\n",
    "\n",
    "This is important in deciding `MAX_TOKEN_COUNT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts = []\n",
    "for _, row in train.iterrows():\n",
    "    tokens = tokenizer.encode(\n",
    "        row[ORIGINAL_TEXT],\n",
    "        max_length=1000,\n",
    "        truncation=True\n",
    "    )\n",
    "    token_counts.append(len(tokens))\n",
    "sns.kdeplot(token_counts)\n",
    "plt.xlabel(\"# Tokens\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Initialize model with pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(MODEL_NAME)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyper-parameters, choose criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKEN_COUNT = 256\n",
    "TRAIN_BATCH = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 1e-05\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
    "saved_models_path = Path(os.path.join(data.current_path, SAVED_MODELS))\n",
    "saved_models_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(\n",
    "    train,\n",
    "    MODEL_NAME,\n",
    "    max_length=MAX_TOKEN_COUNT\n",
    ")\n",
    "valid_dataset = CustomDataset(\n",
    "    valid,\n",
    "    MODEL_NAME,\n",
    "    max_length=MAX_TOKEN_COUNT\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=TRAIN_BATCH, num_workers=NUM_WORKERS)\n",
    "valid_loader = DataLoader(valid_dataset, shuffle=False, batch_size=VALID_BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to device\n",
    "model.to(device)\n",
    "# Lists to keep the losses and evaluation scores at the end of each epoch\n",
    "train_loss, valid_loss = list(), list()\n",
    "for epoch in range(EPOCHS):\n",
    "    # Dummy lists to keep the losses and evaluation scores at the end of each iteration\n",
    "    # (one batch forward and backward process)\n",
    "    train_batch_loss, valid_batch_loss = list(), list()\n",
    "    # Training mode\n",
    "    model.train()\n",
    "    for i, item in enumerate(train_loader):\n",
    "        # Move input to device\n",
    "        input_ids = item[\"input_ids\"].to(device, dtype=torch.long)\n",
    "        attention_mask = item[\"attention_mask\"].to(device, dtype=torch.long)\n",
    "        token_type_ids = item[\"token_type_ids\"].to(device, dtype=torch.long)\n",
    "        target = item[\"target\"].to(device, dtype=torch.float)\n",
    "        # Forward pass\n",
    "        out = model(input_ids, attention_mask, token_type_ids)\n",
    "        # Calculate loss\n",
    "        loss = criterion(out, target)\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Backward pass (backpropogation)\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        # Collect loss and evaluation scores\n",
    "        train_batch_loss.append(loss.item())\n",
    "        message = \\\n",
    "            f\"EPOCH:{epoch+1}/{EPOCHS}, \" + \\\n",
    "            f\"step:{i+1}/{len(train_loader)}, \" + \\\n",
    "            f\"loss={loss.item()}\"\n",
    "        print(\"\\r\", message, end=\"\")\n",
    "    # Take the average of iteration losses and evaluation scores\n",
    "    # and append it to the epoch losses list\n",
    "    train_loss.append(np.array(train_batch_loss).mean())\n",
    "    # Evaluation mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, item in enumerate(valid_loader):\n",
    "            # Move input to device\n",
    "            input_ids = item[\"input_ids\"].to(device, dtype=torch.long)\n",
    "            attention_mask = item[\"attention_mask\"].to(device, dtype=torch.long)\n",
    "            token_type_ids = item[\"token_type_ids\"].to(device, dtype=torch.long)\n",
    "            target = item[\"target\"].to(device, dtype=torch.float)\n",
    "            # Forward pass\n",
    "            out = model(input_ids, attention_mask, token_type_ids)\n",
    "            # Calculate loss\n",
    "            loss = criterion(out, target)\n",
    "            valid_batch_loss.append(loss.item())\n",
    "            message = \\\n",
    "                f\"EPOCH:{epoch+1}/{EPOCHS}, \" + \\\n",
    "                f\"step:{i+1}/{len(valid_loader)}, \" + \\\n",
    "                f\"loss={loss.item()}\"\n",
    "            print(\"\\r\", message, end=\"\")\n",
    "    # Take the average of iteration losses and evaluation scores\n",
    "    # and append it to the epoch losses list\n",
    "    valid_loss.append(np.array(valid_batch_loss).mean())\n",
    "    message = \\\n",
    "        f\"EPOCH:{epoch+1}/{EPOCHS} - \" + \\\n",
    "        f\"Training Loss: {train_loss[-1]}, \" + \\\n",
    "        f\"Validation Loss: {valid_loss[-1]}\"\n",
    "    print(\"\\r\", message)\n",
    "    # Save model\n",
    "    state = f\"epoch_{epoch+1:03}.pth\"\n",
    "    state_dict_path = os.path.join(saved_models_path, state)\n",
    "    torch.save(model.state_dict(), state_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = np.argmin(valid_loss) + 1\n",
    "print(f\"Best epoch: {best_epoch}\")\n",
    "state = f\"epoch_{best_epoch:03}.pth\"\n",
    "state_dict_path = os.path.join(saved_models_path, state)\n",
    "state_dict = torch.load(state_dict_path)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, EPOCHS+1), train_loss, label=\"Train Loss\", color=\"orange\")\n",
    "plt.plot(range(1, EPOCHS+1), valid_loss, label=\"Validation Loss\", color=\"blue\")\n",
    "plt.axvline(x=best_epoch, label=\"Best Epoch\", color=\"darkgreen\", linestyle=\"dashdot\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(f\"Loss\")\n",
    "plt.title(f\"Best Epoch: {best_epoch}\")\n",
    "plt.legend(loc=\"upper right\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = CustomEvaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = CustomDataset(\n",
    "    valid,\n",
    "    MODEL_NAME,\n",
    "    max_length=MAX_TOKEN_COUNT\n",
    ")\n",
    "valid_loader = DataLoader(valid_dataset, shuffle=False, batch_size=1, num_workers=NUM_WORKERS)\n",
    "\n",
    "y_true = []\n",
    "y_pred_probab = []\n",
    "with torch.no_grad():\n",
    "    for i, item in enumerate(valid_loader):\n",
    "        input_ids = item[\"input_ids\"].to(device, dtype=torch.long)\n",
    "        attention_mask = item[\"attention_mask\"].to(device, dtype=torch.long)\n",
    "        token_type_ids = item[\"token_type_ids\"].to(device, dtype=torch.long)\n",
    "        target = item[\"target\"].to(device, dtype=torch.float)\n",
    "\n",
    "        out = model(input_ids, attention_mask, token_type_ids)\n",
    "        out = torch.sigmoid(out)\n",
    "\n",
    "        y_true.append(target.to(\"cpu\").numpy().reshape(-1,))\n",
    "        y_pred_probab.append(out.to(\"cpu\").numpy().reshape(-1,))\n",
    "\n",
    "y_true_val = np.array(y_true).astype(int)\n",
    "y_pred_probab_val = np.array(y_pred_probab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = np.where(y_pred_probab_val > .5, 1, 0)\n",
    "\n",
    "eval.evaluate(y_true=y_true_val, y_pred=y_pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_features[df_features[SPLIT].isin([TEST])].copy()\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "test_dataset = CustomDataset(\n",
    "    test,\n",
    "    MODEL_NAME,\n",
    "    max_length=MAX_TOKEN_COUNT\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=1, num_workers=NUM_WORKERS)\n",
    "\n",
    "y_true = []\n",
    "y_pred_probab = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, item in enumerate(test_loader):\n",
    "        input_ids = item[\"input_ids\"].to(device, dtype=torch.long)\n",
    "        attention_mask = item[\"attention_mask\"].to(device, dtype=torch.long)\n",
    "        token_type_ids = item[\"token_type_ids\"].to(device, dtype=torch.long)\n",
    "        target = item[\"target\"].to(device, dtype=torch.float)\n",
    "\n",
    "        out = model(input_ids, attention_mask, token_type_ids)\n",
    "        out = torch.sigmoid(out)\n",
    "\n",
    "        y_true.append(target.to(\"cpu\").numpy().reshape(-1,))\n",
    "        y_pred_probab.append(out.to(\"cpu\").numpy().reshape(-1,))\n",
    "\n",
    "y_true_test = np.array(y_true).astype(int)\n",
    "y_pred_probab_test = np.array(y_pred_probab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = np.where(y_pred_probab_test > .5, 1, 0)\n",
    "\n",
    "eval.evaluate(y_true=y_true_test, y_pred=y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = test[[ORIGINAL_TEXT, TARGET]].copy()\n",
    "pred_df[PREDICTION] = y_pred_test.reshape(-1,)\n",
    "save_to = os.path.join(data.reports_path, \"roberta-prediction.pkl\")\n",
    "pred_df.to_pickle(save_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract embeddings for test reviews from fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to test set\n",
    "df_features = df_features[df_features[SPLIT].isin([TEST])].copy()\n",
    "df_features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dataset = CustomDataset(\n",
    "    df_features,\n",
    "    MODEL_NAME,\n",
    "    max_length=MAX_TOKEN_COUNT\n",
    ")\n",
    "dataset_loader = DataLoader(dataset, shuffle=False, batch_size=1, num_workers=NUM_WORKERS)\n",
    "\n",
    "y_true = []\n",
    "reviews = []\n",
    "embeddings = []\n",
    "with torch.no_grad():\n",
    "    for i, item in enumerate(dataset_loader):\n",
    "        reviews.append(item[\"text\"])\n",
    "        input_ids = item[\"input_ids\"].to(device, dtype=torch.long)\n",
    "        attention_mask = item[\"attention_mask\"].to(device, dtype=torch.long)\n",
    "        token_type_ids = item[\"token_type_ids\"].to(device, dtype=torch.long)\n",
    "        target = item[\"target\"].to(device, dtype=torch.float)\n",
    "\n",
    "        out = model.l1(input_ids, attention_mask, token_type_ids)\n",
    "        embeddings.append(out.pooler_output.to(\"cpu\").numpy().reshape(-1,))\n",
    "        y_true.append(target.to(\"cpu\").numpy().reshape(-1,))\n",
    "\n",
    "y_true = np.array(y_true).astype(int)\n",
    "reviews = [\"<br>\".join((textwrap.wrap(x[0]))) for x in reviews]\n",
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-Means (Floyd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "inertias = []\n",
    "mapping1 = {}\n",
    "mapping2 = {}\n",
    "K = range(1, 5)\n",
    "\n",
    "for k in tqdm(K):\n",
    "    # Building and fitting the model\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeanModel = kmeans.fit(embeddings)\n",
    "    distortions.append(\n",
    "        sum(np.min(\n",
    "            cdist(embeddings, kmeanModel.cluster_centers_, 'euclidean'),\n",
    "            axis=1\n",
    "        )) / embeddings.shape[0]\n",
    "    )\n",
    "    inertias.append(kmeanModel.inertia_)\n",
    "    mapping1[k] = sum(np.min(\n",
    "        cdist(embeddings, kmeanModel.cluster_centers_, 'euclidean'),\n",
    "        axis=1\n",
    "    )) / embeddings.shape[0]\n",
    "    mapping2[k] = kmeanModel.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12,6), constrained_layout=True)\n",
    "ax[0].plot(K, distortions, 'bx-')\n",
    "ax[0].set_xlabel('k')\n",
    "ax[0].set_ylabel('Distortion')\n",
    "ax[0].set_title('Elbow Method (Distortion)')\n",
    "ax[1].plot(K, inertias, 'bx-')\n",
    "ax[1].set_xlabel('k')\n",
    "ax[1].set_ylabel('Inertia')\n",
    "ax[1].set_title('Elbow Method (Inertia)')\n",
    "fig.suptitle(\"k-Means (Floyd)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elbow method suggests $k=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful constants\n",
    "EMBEDDINGS = [\"llm_{i}\" for i in range(model.l1.config.hidden_size)]\n",
    "CLUSTER = \"cluster\"\n",
    "sentiment_map_inverse = {config.SENTIMENT_MAP[c]: c for c in config.SENTIMENT_MAP}\n",
    "\n",
    "# Utility functions to compute purity of clusters\n",
    "def compute_purity(df):\n",
    "    purity_scores = {}\n",
    "    clusters_unique = df[CLUSTER].unique()\n",
    "    for c in clusters_unique:\n",
    "        labels = df[df[CLUSTER]==c][TARGET].tolist()\n",
    "        sorted_labels = sorted(list(set(labels)), key=labels.count, reverse=True)\n",
    "        mode = sorted_labels[0]\n",
    "        score = sum([1 if y==mode else 0 for y in labels]) / len(labels)\n",
    "        mode_label = sentiment_map_inverse[mode]\n",
    "        purity_scores[c] = (score, mode_label)\n",
    "    return purity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "clustering_method = KMeans(n_clusters=k, random_state=0)\n",
    "clusters = clustering_method.fit(embeddings)\n",
    "\n",
    "embeddings_df = pd.DataFrame(embeddings, columns=EMBEDDINGS)\n",
    "embeddings_df[ORIGINAL_TEXT] = reviews\n",
    "embeddings_df[CLUSTER] = clusters.labels_\n",
    "embeddings_df[TARGET] = y_true.reshape(-1,)\n",
    "\n",
    "scores = compute_purity(embeddings_df)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_reduction_method = TSNE(n_components=2, initialization=\"pca\", learning_rate=\"auto\")\n",
    "embeddings_reduced = dim_reduction_method.fit_transform(embeddings)\n",
    "\n",
    "embeddings_df[\"x\"] = embeddings_reduced[:,0]\n",
    "embeddings_df[\"y\"] = embeddings_reduced[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    embeddings_df,\n",
    "    y=\"y\",\n",
    "    x=\"x\",\n",
    "    color=CLUSTER,\n",
    "    symbol=,\n",
    "    hover_data=[TARGET, ORIGINAL_TEXT],\n",
    "    title=\"k-Means\"\n",
    ")\n",
    "fig.update_layout(uniformtext_mode=\"hide\")\n",
    "fig.update_layout(legend_orientation=\"h\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
